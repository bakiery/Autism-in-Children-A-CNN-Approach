{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load image data from CSV file\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def load_image_data(data_path):\n",
    "    base_path = '/content/drive/MyDrive/autism-data/autism/'\n",
    "    df = pd.read_csv(data_path)\n",
    "\n",
    "    # Load training data\n",
    "    train_df = df[df['dataset'] == 'train']\n",
    "    image_list_train = list(train_df['filepaths'])\n",
    "    imgs = []\n",
    "    imgs_not_found = []\n",
    "    for img in image_list_train:\n",
    "        path = os.path.join(base_path, img)\n",
    "        if os.path.exists(path):\n",
    "            image = Image.open(path)\n",
    "            image = image.resize((256, 256))\n",
    "            imgs.append(np.array(image))\n",
    "        else:\n",
    "            imgs_not_found.append(img)\n",
    "    for img in imgs_not_found:\n",
    "        train_df = train_df[train_df['filepaths'] != img]\n",
    "    X_train = np.array(imgs)\n",
    "    y_train = train_df['labels'].apply(lambda x: 1 if x == 'autistic' else 0)\n",
    "\n",
    "    # Load testing data\n",
    "    test_df = df[df['dataset'] == 'test']\n",
    "    image_list_test = list(test_df['filepaths'])\n",
    "    imgs_test = []\n",
    "    imgs_test_missing = []\n",
    "    for img in image_list_test:\n",
    "        path = os.path.join(base_path, img)\n",
    "        if os.path.exists(path):\n",
    "            image = Image.open(path)\n",
    "            image = image.resize((256, 256))\n",
    "            imgs_test.append(np.array(image))\n",
    "        else:\n",
    "            imgs_test_missing.append(img)\n",
    "    for img in imgs_test_missing:\n",
    "        test_df = test_df[test_df['filepaths'] != img]\n",
    "    X_test = np.array(imgs_test)\n",
    "    y_test = test_df['labels'].apply(lambda x: 1 if x == 'autistic' else 0)\n",
    "\n",
    "    # Load validation data\n",
    "    val_df = df[df['dataset'] == 'valid']\n",
    "    image_list_val = list(val_df['filepaths'])\n",
    "    imgs_val = []\n",
    "    imgs_val_missing = []\n",
    "    for img in image_list_val:\n",
    "        path = os.path.join(base_path, img)\n",
    "        if os.path.exists(path):\n",
    "            image = Image.open(path)\n",
    "            image = image.resize((256, 256))\n",
    "            imgs_val.append(np.array(image))\n",
    "        else:\n",
    "            imgs_val_missing.append(img)\n",
    "    for img in imgs_val_missing:\n",
    "        val_df = val_df[val_df['filepaths'] != img]\n",
    "    X_val = np.array(imgs_val)\n",
    "    y_val = val_df['labels'].apply(lambda x: 1 if x == 'autistic' else 0)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, X_val, y_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define the model architecture\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, layers\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "\n",
    "def load_own_model():\n",
    "    model = Sequential()\n",
    "    model.add(Rescaling(1./255, input_shape=(256, 256, 3)))\n",
    "\n",
    "    model.add(layers.Conv2D(16, kernel_size=10, activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(3))\n",
    "\n",
    "    model.add(layers.Conv2D(32, kernel_size=8, activation=\"relu\"))\n",
    "    model.add(layers.MaxPooling2D(3))\n",
    "\n",
    "    model.add(layers.Conv2D(32, kernel_size=6, activation=\"relu\"))\n",
    "    model.add(layers.Conv2D(32, kernel_size=6, activation=\"relu\"))\n",
    "    model.add(layers.MaxPooling2D(3))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Train the model\n",
    "\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def train_model(model, X_train, y_train, X_val, y_val):\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    early_stopping = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, batch_size=32, callbacks=[early_stopping])\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Perform facial assessment using the trained model\n",
    "\n",
    "import base64\n",
    "import requests\n",
    "import streamlit as st\n",
    "\n",
    "def perform_facial_assessment(image):\n",
    "    # Convert image to base64\n",
    "    image_base64 = base64.b64encode(image).decode('utf-8')\n",
    "\n",
    "    # Send image to the API for preprocessing and prediction\n",
    "    api_url = 'https://your-api-url/predict'\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    payload = {'image': image_base64}\n",
    "    response = requests.post(api_url, headers=headers, json=payload)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        # Get the prediction result from the response\n",
    "        result = response.json()['result']\n",
    "        probability = response.json()['probability']\n",
    "\n",
    "        # Display the result\n",
    "        st.subheader('Detection Result:')\n",
    "        st.success(f'Likelihood of being autistic: {probability:.2f}')\n",
    "        st.info(f'Classification: {result}')\n",
    "    else:\n",
    "        st.error('Error occurred while processing the image.')\n",
    "\n",
    "    # Display the uploaded image\n",
    "    st.image(image, caption='Uploaded Image', use_column_width=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Create the Streamlit app\n",
    "\n",
    " def main():\n",
    "    st.set_page_config(\n",
    "        page_title=\"Facial Assessment Tool\",\n",
    "        page_icon=\"ðŸ§©\",\n",
    "        layout=\"centered\",\n",
    "        initial_sidebar_state=\"collapsed\",\n",
    "    )\n",
    "\n",
    "    st.title('Facial Assessment Tool')\n",
    "\n",
    "    # Display the introduction and instructions\n",
    "    st.markdown('''\n",
    "        ## Facial Assessment Tool\n",
    "        Upload an image of a child to assess the likelihood of autism based on facial morphology.\n",
    "        ''')\n",
    "\n",
    "    # Upload image\n",
    "    uploaded_file = st.file_uploader('Upload an image', type=['jpg', 'jpeg', 'png'])\n",
    "\n",
    "    if uploaded_file is not None:\n",
    "        # Read image file\n",
    "        image = uploaded_file.read()\n",
    "\n",
    "        # Perform facial assessment using the trained model\n",
    "        perform_facial_assessment(image)\n",
    "\n",
    "    # Citation\n",
    "    st.markdown('''\n",
    "        This tool is based on research papers conducted by Naomi Scott, Alex Lee Jones, Robin Stewart Samuel Kramer, Robert Ward, Mohammad-Parsa Hosseini, Madison Beary, Alex Hadsell, \n",
    "        Ryan Messersmith, Hamid Soltanian-Zadeh, K.K. Mujeeb Rahman and M. Monica Subashini. You can find the studies at the following links:\n",
    "        \n",
    "        - [Bangor University Study](https://ward-lab.bangor.ac.uk/pubs/Scott_Ward_14_AQ.pdf)\n",
    "        - [Deep Learning for Autism Diagnosis and Facial Analysis in Children](https://www.frontiersin.org/articles/10.3389/fncom.2021.789998/full)\n",
    "        - [Identification of Autism in Children Using Static Facial Features and Deep Neural Networks](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8773918/)\n",
    "        \n",
    "        Please note that this tool is provided for informational purposes only and is not a diagnostic tool. It assesses the likelihood of autism based on facial morphology, but a formal diagnosis should be made by a qualified healthcare professional.\n",
    "        ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Step 6: Load image data\n",
    "    data_path = '/content/drive/MyDrive/autism-data/autism.csv'\n",
    "    X_train, y_train, X_test, y_test, X_val, y_val = load_image_data()\n",
    "\n",
    "    # Step 7: Load the model\n",
    "    model = load_own_model()\n",
    "\n",
    "    # Step 8: Train the model\n",
    "    trained_model, history = train_model(model, X_train, y_train, X_val, y_val)\n",
    "\n",
    "    # Step 9: Run the Streamlit app\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autism",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
